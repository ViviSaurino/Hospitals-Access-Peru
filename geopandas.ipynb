{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e05b49",
   "metadata": {},
   "source": [
    "# Geospatial Analysis — Hospitals in Peru (GeoPandas)\n",
    "\n",
    "**Author:** _Your Name_\n",
    "\n",
    "**Objective:** Clean IPRESS data and produce GeoPandas outputs for team visualizations (Folium & Streamlit).\n",
    "\n",
    "## What this notebook does\n",
    "1. **Data cleaning** of IPRESS (MINSA) operational hospitals:\n",
    "\n",
    "   - Keep only operational hospitals (filter by *situacion/condicion* containing \"FUNCION\").\n",
    "\n",
    "   - Rename `NORTE -> LATITUD` and `ESTE -> LONGITUD`.\n",
    "\n",
    "   - Convert coordinates to numeric and keep valid Peru ranges.\n",
    "\n",
    "   - Save → `data/processed/hospitales_clean.csv`.\n",
    "\n",
    "2. **Task 1 — Static Maps (Hospital count by district):**\n",
    "\n",
    "   - Spatial join Hospitals ↔ District polygons.\n",
    "\n",
    "   - Export GeoJSONs: `district_counts.geojson`, `district_zero.geojson`, `district_top10.geojson`.\n",
    "\n",
    "3. **Task 2 — Department-level analysis:**\n",
    "\n",
    "   - Aggregate counts by department.\n",
    "\n",
    "   - Save → `department_counts.csv`.\n",
    "\n",
    "4. **Task 3 — Proximity (10 km) using Population Centers:**\n",
    "\n",
    "   - For **Lima** and **Loreto**, compute 10 km buffers around each population center and count hospitals inside.\n",
    "\n",
    "   - Export buffers (min & max density) and summary CSVs for Folium/Streamlit.\n",
    "\n",
    "   \n",
    "> All final files are saved in the `salida/` folder for Folium (choropleths, clusters, and 10 km circles) and for Streamlit (tabs 2 & 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e517bf",
   "metadata": {},
   "source": [
    "## 0) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Make folders if missing\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "os.makedirs(\"salida\", exist_ok=True)\n",
    "\n",
    "# Paths (relative to repo root)\n",
    "P_IPRESS = \"data/ipress_raw.csv\"          # <-- Your raw IPRESS CSV (without tildes ideally)\n",
    "P_DIST   = \"data/distritos.zip\"           # <-- Zipped shapefile: distritos (INEI)\n",
    "P_CP     = \"data/centros_poblados.zip\"    # <-- Zipped shapefile: centros poblados (INEI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13276e",
   "metadata": {},
   "source": [
    "## 1) Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f917f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: normalize column names (lowercase, ascii, underscores) ---\n",
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (df.columns\n",
    "                  .str.strip()\n",
    "                  .map(lambda x: unicodedata.normalize(\"NFKD\", x))\n",
    "                  .str.encode(\"ascii\", \"ignore\").str.decode(\"utf-8\")\n",
    "                  .str.lower()\n",
    "                  .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "                  .str.strip(\"_\"))\n",
    "    return df\n",
    "\n",
    "# --- Helper: try to find a column by candidates / substrings (case-insensitive) ---\n",
    "def find_col(columns, candidates):\n",
    "    cols = [c.lower() for c in columns]\n",
    "    for cand in candidates:\n",
    "        lc = cand.lower()\n",
    "        for c in columns:\n",
    "            if lc == c.lower():\n",
    "                return c\n",
    "        # substring fallback\n",
    "        for c in columns:\n",
    "            if lc in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "# --- Helper: strip accents and uppercase for robust comparisons ---\n",
    "def up_noacc(s):\n",
    "    if pd.isna(s): return s\n",
    "    s = unicodedata.normalize(\"NFKD\", str(s))\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    return s.upper().strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71762b",
   "metadata": {},
   "source": [
    "## 2) Load & clean IPRESS (MINSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1) Load raw IPRESS data (CSV). If you have Excel, change to pd.read_excel.\n",
    "df_raw = pd.read_csv(P_IPRESS, dtype=str, encoding=\"utf-8\")\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "\n",
    "# 2.2) Optional: replace comma decimal separators before numeric conversion\n",
    "for c in [\"Latitud\",\"Longitud\",\"NORTE\",\"ESTE\"]:\n",
    "    if c in df_raw.columns and df_raw[c].dtype == \"object\":\n",
    "        df_raw[c] = df_raw[c].str.replace(\",\", \".\", regex=False)\n",
    "\n",
    "# 2.3) Rename columns to standard (handles variants and your 'NORTE'/'ESTE' case)\n",
    "rename_map = {\n",
    "    # Spanish originals (no tildes to help matching)\n",
    "    \"Institucion\"               : \"INSTITUCION\",\n",
    "    \"Nombre del Establecimiento\": \"NOMBRE_DEL_ESTABLECIMIENTO\",\n",
    "    \"Nombre d\"                  : \"NOMBRE_DEL_ESTABLECIMIENTO\",\n",
    "    \"Clasificacion\"             : \"CLASIFICACION\",\n",
    "    \"Clasifica\"                 : \"CLASIFICACION\",\n",
    "    \"Departamento\"              : \"DEPARTAMENTO\",\n",
    "    \"Departam\"                  : \"DEPARTAMENTO\",\n",
    "    \"Provincia\"                 : \"PROVINCIA\",\n",
    "    \"Distrito\"                  : \"DISTRITO\",\n",
    "    \"Estado\"                    : \"ESTADO\",\n",
    "    \"Latitud\"                   : \"LATITUD\",\n",
    "    \"Longitud\"                  : \"LONGITUD\",\n",
    "    \"NORTE\"                     : \"LATITUD\",\n",
    "    \"ESTE\"                      : \"LONGITUD\",\n",
    "}\n",
    "# Apply renaming only for present columns\n",
    "df = df_raw.rename(columns={k:v for k,v in rename_map.items() if k in df_raw.columns}).copy()\n",
    "\n",
    "# 2.4) Filter operational hospitals (search in any column named 'situacion' or 'condicion')\n",
    "op_cols = [c for c in df.columns if re.search(r\"(situaci|condici)\", c, flags=re.I)]\n",
    "if op_cols:\n",
    "    mask = False\n",
    "    for c in op_cols:\n",
    "        mask = mask | df[c].astype(str).str.contains(\"FUNCION\", case=False, na=False)\n",
    "    df = df[mask].copy()\n",
    "\n",
    "# 2.5) Keep only the required minimal columns\n",
    "keep = [\"INSTITUCION\",\"NOMBRE_DEL_ESTABLECIMIENTO\",\"CLASIFICACION\",\n",
    "        \"DEPARTAMENTO\",\"PROVINCIA\",\"DISTRITO\",\"ESTADO\",\"LATITUD\",\"LONGITUD\"]\n",
    "present = [c for c in keep if c in df.columns]\n",
    "missing  = [c for c in keep if c not in df.columns]\n",
    "print(\"Present columns:\", present)\n",
    "if missing:\n",
    "    print(\"WARNING - Missing expected columns:\", missing)\n",
    "\n",
    "df = df[present].copy()\n",
    "\n",
    "# 2.6) Convert coordinates to numeric and keep valid Peru ranges\n",
    "for c in [\"LATITUD\",\"LONGITUD\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Peru rough bounding box: lat (−20..5), lon (−90..−60)\n",
    "if set([\"LATITUD\",\"LONGITUD\"]).issubset(df.columns):\n",
    "    df = df[\n",
    "        df[\"LATITUD\"].between(-20, 5) &\n",
    "        df[\"LONGITUD\"].between(-90, -60)\n",
    "    ].dropna(subset=[\"LATITUD\",\"LONGITUD\"])\n",
    "\n",
    "print(\"Clean shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b9bac",
   "metadata": {},
   "source": [
    "### 2.7) Save cleaned hospitals → `data/processed/hospitales_clean.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cdc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_clean = \"data/processed/hospitales_clean.csv\"\n",
    "df.to_csv(out_clean, index=False, encoding=\"utf-8\")\n",
    "print(\"Saved:\", out_clean, \"rows:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437d2dc",
   "metadata": {},
   "source": [
    "## 3) Hospitals → GeoDataFrame (EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d20816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure required columns for geometry\n",
    "assert \"LATITUD\" in df.columns and \"LONGITUD\" in df.columns, \"LATITUD/LONGITUD missing after cleaning.\"\n",
    "\n",
    "gdf_h = gpd.GeoDataFrame(\n",
    "    df.copy(),\n",
    "    geometry=gpd.points_from_xy(df[\"LONGITUD\"], df[\"LATITUD\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf_h.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50261e",
   "metadata": {},
   "source": [
    "## 4) Read Districts & Population Centers shapefiles (INEI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read zipped shapefiles directly\n",
    "gdf_dist = gpd.read_file(f\"zip://{P_DIST}\")\n",
    "if gdf_dist.crs is None or gdf_dist.crs.to_string() != \"EPSG:4326\":\n",
    "    gdf_dist = gdf_dist.to_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf_cp = gpd.read_file(f\"zip://{P_CP}\")\n",
    "if gdf_cp.crs is None or gdf_cp.crs.to_string() != \"EPSG:4326\":\n",
    "    gdf_cp = gdf_cp.to_crs(\"EPSG:4326\")\n",
    "\n",
    "print(\"Districts:\", gdf_dist.shape, gdf_dist.crs)\n",
    "print(\"Pop. Centers:\", gdf_cp.shape, gdf_cp.crs)\n",
    "\n",
    "# Try to detect district & department columns in the districts layer\n",
    "dist_col = find_col(gdf_dist.columns, [\"DISTRITO\",\"NOMB_DIST\",\"NOMBDIST\",\"DIST\"])\n",
    "dept_col = find_col(gdf_dist.columns, [\"DEPARTAMEN\",\"DEPARTAMENTO\",\"NOMBDEP\",\"DPTO\",\"DEPART\"])\n",
    "print(\"Detected fields → District:\", dist_col, \"| Department:\", dept_col)\n",
    "assert dist_col and dept_col, \"Cannot detect district/department columns in districts shapefile.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a38e06",
   "metadata": {},
   "source": [
    "## 5) Task 1 — Hospital Count by District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1) Spatial join: assign each hospital to a district polygon\n",
    "joined = gpd.sjoin(\n",
    "    gdf_h,\n",
    "    gdf_dist[[dist_col, dept_col, \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "# 5.2) Count hospitals by district (with department as grouping)\n",
    "dist_counts = (joined\n",
    "               .groupby([dept_col, dist_col], dropna=False)\n",
    "               .size().reset_index(name=\"hospitales\"))\n",
    "\n",
    "# 5.3) Merge counts back to district polygons\n",
    "gdf_dist_cnt = gdf_dist.merge(dist_counts, on=[dept_col, dist_col], how=\"left\")\n",
    "gdf_dist_cnt[\"hospitales\"] = gdf_dist_cnt[\"hospitales\"].fillna(0).astype(int)\n",
    "\n",
    "# 5.4) Export GeoJSONs for Folium\n",
    "gdf_dist_cnt.to_file(\"salida/district_counts.geojson\", driver=\"GeoJSON\")\n",
    "gdf_dist_cnt[gdf_dist_cnt[\"hospitales\"]==0].to_file(\"salida/district_zero.geojson\", driver=\"GeoJSON\")\n",
    "gdf_dist_cnt.sort_values(\"hospitales\", ascending=False).head(10)            .to_file(\"salida/district_top10.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"Saved: salida/district_counts.geojson, district_zero.geojson, district_top10.geojson\")\n",
    "gdf_dist_cnt[[\"hospitales\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93f3c2",
   "metadata": {},
   "source": [
    "## 6) Task 2 — Department-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1) Aggregate by department using hospitals table (textual field from IPRESS)\n",
    "dep_text_col = find_col(gdf_h.columns, [\"DEPARTAMENTO\",\"DEPARTAMEN\",\"DEPTO\",\"REGION\",\"AMBITO\"])\n",
    "assert dep_text_col, \"Cannot detect a department-like column in hospitals data.\"\n",
    "\n",
    "dep_tbl = (gdf_h.groupby(dep_text_col).size()\n",
    "           .reset_index(name=\"hospitales\")\n",
    "           .sort_values(\"hospitales\", ascending=False))\n",
    "\n",
    "# 6.2) Save CSV for Streamlit (table + chart)\n",
    "dep_tbl.to_csv(\"salida/department_counts.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Saved: salida/department_counts.csv\")\n",
    "dep_tbl.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d87db1",
   "metadata": {},
   "source": [
    "## 7) Task 3 — Proximity (10 km) using Population Centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90865f1c",
   "metadata": {},
   "source": [
    "**Regions to analyze:** Lima and Loreto.\n",
    "\n",
    "**Method:**\n",
    "\n",
    "- Detect department column in population centers.\n",
    "\n",
    "- For each region (Lima/Loreto):\n",
    "\n",
    "  1) Filter population centers in that department.\n",
    "\n",
    "  2) Reproject to `EPSG:32718` (meters), compute 10 km buffers.\n",
    "\n",
    "  3) Count hospitals within each buffer.\n",
    "\n",
    "  4) Export GeoJSONs for the **min** and **max** hospital densities and a summary CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55089bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1) Detect department column in population centers\n",
    "cp_dept_col = find_col(gdf_cp.columns, [\"DEPARTAMEN\",\"DEPARTAMENTO\",\"NOMBDEP\",\"DPTO\",\"DEPART\"])\n",
    "if not cp_dept_col:\n",
    "    raise ValueError(\"Department column not found in Population Centers shapefile. Please inspect gdf_cp.columns.\")\n",
    "\n",
    "# 7.2) Prepare metric projections\n",
    "h_m  = gdf_h.to_crs(\"EPSG:32718\")\n",
    "cp_m = gdf_cp.to_crs(\"EPSG:32718\")\n",
    "\n",
    "regions = [\"LIMA\", \"LORETO\"]\n",
    "summary_rows = []\n",
    "\n",
    "def export_proximity_for_region(reg_upper):\n",
    "    # Filter CP by department (accent/case-insensitive)\n",
    "    sel = gdf_cp[cp_dept_col].map(up_noacc) == reg_upper\n",
    "    cp_reg4326 = gdf_cp[sel].copy()\n",
    "    if cp_reg4326.empty:\n",
    "        print(f\"[WARN] No population centers found for department: {reg_upper}\")\n",
    "        return None\n",
    "\n",
    "    # Work in meters for buffers\n",
    "    cp_reg = cp_reg4326.to_crs(\"EPSG:32718\").copy()\n",
    "    # If CP geometry are not points, use centroids\n",
    "    cp_reg[\"centroid\"] = cp_reg.geometry.centroid\n",
    "    cp_reg = gpd.GeoDataFrame(cp_reg.drop(columns=\"geometry\"), geometry=cp_reg[\"centroid\"], crs=\"EPSG:32718\")\n",
    "\n",
    "    # 10 km buffer\n",
    "    cp_reg[\"buffer10\"] = cp_reg.geometry.buffer(10000)\n",
    "    buffers = gpd.GeoDataFrame(cp_reg.drop(columns=\"geometry\"), geometry=cp_reg[\"buffer10\"], crs=\"EPSG:32718\")\n",
    "\n",
    "    # Count hospitals within each buffer\n",
    "    counts = gpd.sjoin(buffers, h_m, how=\"left\", predicate=\"contains\")\\\n",
    "                .groupby(buffers.index).size().reindex(buffers.index, fill_value=0)\n",
    "    buffers[\"hosp_10km\"] = counts.values\n",
    "\n",
    "    # Find extremes\n",
    "    fewest = buffers.sort_values(\"hosp_10km\", ascending=True).head(1)\n",
    "    most   = buffers.sort_values(\"hosp_10km\", ascending=False).head(1)\n",
    "\n",
    "    # Export GeoJSONs (back to EPSG:4326)\n",
    "    fewest4326 = fewest.to_crs(\"EPSG:4326\")\n",
    "    most4326   = most.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    fewest_path = f\"salida/proximity_buffers_{reg_upper.lower()}_min.geojson\"\n",
    "    most_path   = f\"salida/proximity_buffers_{reg_upper.lower()}_max.geojson\"\n",
    "    fewest4326.to_file(fewest_path, driver=\"GeoJSON\")\n",
    "    most4326.to_file(most_path, driver=\"GeoJSON\")\n",
    "\n",
    "    # Also export hospitals inside each selected buffer (for Folium)\n",
    "    h_in_fewest = gpd.sjoin(gdf_h, fewest4326[[\"geometry\"]], how=\"inner\", predicate=\"within\")\n",
    "    h_in_most   = gpd.sjoin(gdf_h, most4326[[\"geometry\"]],   how=\"inner\", predicate=\"within\")\n",
    "    h_in_fewest.to_file(f\"salida/proximity_hospitals_{reg_upper.lower()}_min.geojson\", driver=\"GeoJSON\")\n",
    "    h_in_most.to_file(f\"salida/proximity_hospitals_{reg_upper.lower()}_max.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "    print(\"Saved:\", fewest_path, \"and\", most_path)\n",
    "    return int(fewest[\"hosp_10km\"].iloc[0]), int(most[\"hosp_10km\"].iloc[0])\n",
    "\n",
    "for reg in regions:\n",
    "    res = export_proximity_for_region(reg)\n",
    "    if res:\n",
    "        mn, mx = res\n",
    "        summary_rows.append({\"region\": reg.title(), \"min_hosp_10km\": mn, \"max_hosp_10km\": mx})\n",
    "\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "summary.to_csv(\"salida/proximity_summary.csv\", index=False, encoding=\"utf-8\")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916881e",
   "metadata": {},
   "source": [
    "## 8) Files produced (for your team)\n",
    "\n",
    "**Processed base data**\n",
    "\n",
    "- `data/processed/hospitales_clean.csv`\n",
    "\n",
    "**Task 1 (district level)**\n",
    "\n",
    "- `salida/district_counts.geojson`\n",
    "\n",
    "- `salida/district_zero.geojson`\n",
    "\n",
    "- `salida/district_top10.geojson`\n",
    "\n",
    "**Task 2 (department level)**\n",
    "\n",
    "- `salida/department_counts.csv`\n",
    "\n",
    "**Task 3 (proximity, 10 km)**\n",
    "\n",
    "- `salida/proximity_buffers_lima_min.geojson`, `salida/proximity_buffers_lima_max.geojson`\n",
    "\n",
    "- `salida/proximity_buffers_loreto_min.geojson`, `salida/proximity_buffers_loreto_max.geojson`\n",
    "\n",
    "- `salida/proximity_hospitals_lima_min.geojson`, `salida/proximity_hospitals_lima_max.geojson`\n",
    "\n",
    "- `salida/proximity_hospitals_loreto_min.geojson`, `salida/proximity_hospitals_loreto_max.geojson`\n",
    "\n",
    "- `salida/proximity_summary.csv`\n",
    "\n",
    "> These are ready to be used by your teammates in **Folium** (choropleths, clusters, 10 km buffers) and **Streamlit** (tabs 2 & 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f121b0",
   "metadata": {},
   "source": [
    "## 9) Quick Visual Previews (optional)\n",
    "\n",
    "These cells generate **inline previews** so you can see results directly in Jupyter.\n",
    "They are not required for the export files, but they're helpful for QA.\n",
    "\n",
    "- Static choropleth preview (district counts) — `matplotlib`\n",
    "- Department bar chart (Top 10) — `matplotlib`\n",
    "- Folium preview maps — hospitals sample and Lima proximity buffers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 9.1) Static choropleth preview for district counts\n",
    "fig = plt.figure(figsize=(7, 8))\n",
    "ax = plt.gca()\n",
    "_ = gdf_dist_cnt.plot(column=\"hospitales\", legend=True, ax=ax)\n",
    "ax.set_title(\"Hospitals per District — preview\")\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "# 9.2) Department bar chart (Top 10)\n",
    "fig = plt.figure(figsize=(7, 6))\n",
    "ax = plt.gca()\n",
    "(dep_tbl.head(10).sort_values(\"hospitales\", ascending=True)\n",
    " .plot(kind=\"barh\", x=dep_text_col, y=\"hospitales\", ax=ax))\n",
    "ax.set_title(\"Hospitals by Department — Top 10 (preview)\")\n",
    "ax.set_xlabel(\"Hospitals\")\n",
    "ax.set_ylabel(\"Department\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# 9.3) Folium — hospital points (sample up to 1000 for speed)\n",
    "if not gdf_h.empty:\n",
    "    center = [float(gdf_h['LATITUD'].mean()), float(gdf_h['LONGITUD'].mean())]\n",
    "    m_points = folium.Map(location=center, zoom_start=5, tiles=\"cartodbpositron\")\n",
    "    mc = MarkerCluster().add_to(m_points)\n",
    "\n",
    "    sample_n = min(1000, len(gdf_h))\n",
    "    for _, r in gdf_h.sample(sample_n, random_state=42).iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[float(r['LATITUD']), float(r['LONGITUD'])],\n",
    "            radius=3, fill=True, weight=1,\n",
    "            popup=str(r.get('NOMBRE_DEL_ESTABLECIMIENTO', 'Hospital'))\n",
    "        ).add_to(mc)\n",
    "    m_points\n",
    "else:\n",
    "    print(\"No hospital points to preview.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f32b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.4) Folium — Lima proximity buffers preview (min & max)\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "lima_min_fp = \"salida/proximity_buffers_lima_min.geojson\"\n",
    "lima_max_fp = \"salida/proximity_buffers_lima_max.geojson\"\n",
    "h_lima_min_fp = \"salida/proximity_hospitals_lima_min.geojson\"\n",
    "h_lima_max_fp = \"salida/proximity_hospitals_lima_max.geojson\"\n",
    "\n",
    "if all(os.path.exists(p) for p in [lima_min_fp, lima_max_fp, h_lima_min_fp, h_lima_max_fp]):\n",
    "    lima_min = gpd.read_file(lima_min_fp)\n",
    "    lima_max = gpd.read_file(lima_max_fp)\n",
    "    h_lima_min = gpd.read_file(h_lima_min_fp)\n",
    "    h_lima_max = gpd.read_file(h_lima_max_fp)\n",
    "\n",
    "    # Map center: mean of all hospital points in these layers (fallback to Peru center if empty)\n",
    "    if not h_lima_max.empty:\n",
    "        center = [float(h_lima_max.geometry.y.mean()), float(h_lima_max.geometry.x.mean())]\n",
    "    else:\n",
    "        center = [-9.2, -75.0]\n",
    "\n",
    "    m_lima = folium.Map(location=center, zoom_start=7, tiles=\"cartodbpositron\")\n",
    "    folium.GeoJson(lima_min).add_to(m_lima)\n",
    "    folium.GeoJson(lima_max).add_to(m_lima)\n",
    "\n",
    "    for gdf_pts in [h_lima_min, h_lima_max]:\n",
    "        for _, r in gdf_pts.iterrows():\n",
    "            folium.CircleMarker(location=[float(r.geometry.y), float(r.geometry.x)],\n",
    "                                radius=2, fill=True, weight=0.5).add_to(m_lima)\n",
    "    m_lima\n",
    "else:\n",
    "    print(\"Lima proximity files not found yet. Run Task 3 cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c80e0b",
   "metadata": {},
   "source": [
    "## 10) Task 1 — Static Maps (PNG exports)\n",
    "\n",
    "This section produces the **three static maps** required by Task 1 using **GeoPandas + Matplotlib**, and saves them into the `salida/` folder:\n",
    "\n",
    "- `map1_district_counts.png` → total public hospitals per district (choropleth).\n",
    "- `map2_district_zero.png`   → districts with **zero** hospitals highlighted.\n",
    "- `map3_district_top10.png`  → **Top 10** districts with the highest number of hospitals.\n",
    "\n",
    "> Run the earlier cells first (especially Task 1 join) so `gdf_dist_cnt` exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"salida\", exist_ok=True)\n",
    "\n",
    "# Safety checks\n",
    "assert 'gdf_dist_cnt' in globals(), \"Run Task 1 cells first to create gdf_dist_cnt.\"\n",
    "assert 'dist_col' in globals() and 'dept_col' in globals(), \"District/Department fields not detected.\"\n",
    "\n",
    "# -------- Map 1: Total hospitals per district (choropleth) --------\n",
    "fig = plt.figure(figsize=(8, 9))\n",
    "ax = plt.gca()\n",
    "gdf_dist_cnt.plot(column=\"hospitales\", legend=True, ax=ax)  # default colormap, no manual colors\n",
    "ax.set_title(\"Map 1 — Hospitals per District (Total)\")\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"salida/map1_district_counts.png\", dpi=220)\n",
    "plt.show()\n",
    "\n",
    "# -------- Map 2: Highlight districts with zero hospitals --------\n",
    "gdf_zero = gdf_dist_cnt[gdf_dist_cnt[\"hospitales\"] == 0]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 9))\n",
    "ax = plt.gca()\n",
    "# base layer faint\n",
    "gdf_dist_cnt.plot(ax=ax, alpha=0.12)            # light background\n",
    "# overlay zeros (default style, thicker borders to stand out)\n",
    "gdf_zero.plot(ax=ax, linewidth=1.0)             # defaults; no explicit colors\n",
    "ax.set_title(\"Map 2 — Districts with ZERO Hospitals (highlighted)\")\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"salida/map2_district_zero.png\", dpi=220)\n",
    "plt.show()\n",
    "\n",
    "# -------- Map 3: Top 10 districts with highest number of hospitals --------\n",
    "top10 = gdf_dist_cnt.sort_values(\"hospitales\", ascending=False).head(10)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 9))\n",
    "ax = plt.gca()\n",
    "# base layer faint\n",
    "gdf_dist_cnt.plot(ax=ax, alpha=0.12)\n",
    "# overlay top10 (default style, thicker borders)\n",
    "top10.plot(ax=ax, linewidth=1.2)\n",
    "ax.set_title(\"Map 3 — Top 10 Districts by Number of Hospitals\")\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"salida/map3_district_top10.png\", dpi=220)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved PNGs to 'salida/':\",\n",
    "      \"\\n - map1_district_counts.png\",\n",
    "      \"\\n - map2_district_zero.png\",\n",
    "      \"\\n - map3_district_top10.png\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}